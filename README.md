# ğŸ“š QA-ChatBot â€“ AI-Powered Chatbot with Gemini API, FastAPI & Streamlit

Welcome!  
This repository contains the complete source code and setup instructions for **QA-ChatBot** â€“ an AI chatbot built with the Gemini API as its brain, using **FastAPI** for the backend, and **Streamlit** for an intuitive web-based frontend.

This project is designed to help you learn how to integrate modern generative AI APIs into a full-stack Python application.

---

## âœ¨ Overview

**QA-ChatBot** is:
- âš¡ Lightweight and fast, thanks to FastAPI.
- ğŸ§  Powered by Google's Gemini API to generate human-like responses.
- ğŸ–¼ï¸ Visual and interactive, thanks to the Streamlit frontend.
- ğŸ› ï¸ Easy to configure and extend, so you can experiment or build your own features on top.

---

## ğŸ¯ Goals & Motivation

This project was created to:
- Demonstrate how to connect a **FastAPI backend** with a **Streamlit frontend**.
- Explore real-time AI chat powered by an external LLM (Gemini).
- Learn best practices in Python API development and deployment.
- Serve as a starter template for more advanced chatbot ideas.

---

## ğŸ“¦ Project Structure

```plaintext
.
ai_chat_project/
â”œâ”€â”€ README.md                  # ğŸ“š Project documentation
â”œâ”€â”€ .gitignore                 # ğŸš« Files & folders to ignore in Git
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                # ğŸš€ FastAPI backend entry point
â”‚   â”œâ”€â”€ chat_model.py          # ğŸ§  Chat logic (rule-based or model integration)
â”‚   â””â”€â”€ requirements.txt       # ğŸ“¦ Backend Python dependencies
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                 # ğŸ¨ Streamlit frontend app
â””â”€â”€ Dockerfile                 # ğŸ³ Dockerfile to build container image
